document.getElementById("title").innerHTML = "Search Engines"
document.getElementById("blogp1").innerHTML = "Before the dawn of search engines, in order to search for information, one must actually go to the library, check out the card catalogues and work your way from there. Obviously, though card catalogues were essentially effective, it was not at all efficient for it can take some time to arrive at the particular piece of information that someone is looking for. However, before Google made everyone’s lives easy, the Internet was a collection of File Transfer Protocol (FTP) sites wherein users would look through specific shared files. Eventually, the list of web servers available in the internet increased, and so it was necessary to organize the data files on FTP. In essence, the main goal of search engines to organize data in the Internet and to make it easier to navigate through the web servers and files on the internet.  "
document.getElementById("blogp2").innerHTML = "Archie was the very first search engine which was developed by Alan Emtage as a school project. Initially, Archie were merely archives stored on anonymous FTP web sites in a certain network of computers. Back then, this search engine did not have the capacity to search for keywords as used in the present modern search engines. In 1993, Matthew Gray developed Wandex, the first search engine that pretty much works the same way as search engines work today, it was the technology that first “crawled the web indexing and searching the catalog of indexed pages on the web.” Eventually, in 1994 WebCrawler’s search engine began indexing the full text of web sites instead of just web page titles."
document.getElementById("blogp3").innerHTML = "Web crawlers are literally like spiders that systematically crawls through the web for information for the purpose of web indexing. Web indexing on the other hand refers to various methods for indexing the contents of a website or of the Internet as a whole. So when a person searches something using the search engines, the spiders will crawl through the index of the search engine and it will return results that are relevant and it will rank the results based on the popularity of the websites providing the information. When the engines find these pages, they decipher the code from them and store selected pieces in massive databases, to be recalled later when needed for a search query. "
document.getElementById("blogp4").innerHTML = "Google has a system in how to decide which among the thousands of pages are considered relevant for the searcher. Founded by Larry Page and Sergey Brin, the page ranking system ranks the pages according to its relevance to the searcher by looking at how many outside links point to it and how important those links are. These factors are combined to produce the page’s over all score. In order for some pages to gain high ranking, they use the search engine optimization (SEO); a process to increase the amount of visitors to a website. It is both relevance and popularity that the process of SEO is meant to influence."